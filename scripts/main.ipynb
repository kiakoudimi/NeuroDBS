{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ff7533",
   "metadata": {},
   "source": [
    "### DBS-ON/OFF states classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ee1f8",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functions import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3e1c7",
   "metadata": {},
   "source": [
    "#### File paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "mask_img = nib.load(\"../data/msk/sum_80_bin.nii\")\n",
    "measures = [\"ALFF\", \"fALFF\", \"ECM_add\", \"ECM_deg\", \"ECM_norm\", \"ECM_rank\", \"GCOR\", \"ICC\", \"IHC\", \"LCOR\"]\n",
    "output_dir = \"../results/scores/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf01e18",
   "metadata": {},
   "source": [
    "#### Run optimization with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid space\n",
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(random_state=124, max_iter=5000),\n",
    "        \"params\": {\"clf__C\": np.logspace(-2, 2, 5), \"clf__solver\": [\"lbfgs\", \"liblinear\", \"saga\"]},\n",
    "    },\n",
    "    \"LDA\": {\n",
    "        \"model\": LinearDiscriminantAnalysis(),\n",
    "        \"params\": {\n",
    "            \"clf__tol\": [1e-4, 1e-3, 1e-2],\n",
    "        },\n",
    "    },\n",
    "    \"Naive Bayes\": {\"model\": GaussianNB(), \"params\": {\"clf__var_smoothing\": np.logspace(0, -9, num=10)}},\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=124),\n",
    "        \"params\": {\"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"], \"clf__max_depth\": [3, 5, 10]},\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=124),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [100, 1000],\n",
    "            \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            \"clf__max_depth\": [3, 5, 10],\n",
    "        },\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=124),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [100, 1000],\n",
    "            \"clf__max_depth\": [3, 5, 10],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "        },\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=124),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [100, 1000],\n",
    "            \"clf__max_depth\": [3, 5, 10],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "        },\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(probability=True, random_state=124),\n",
    "        \"params\": {\"clf__C\": np.logspace(-2, 2, 5), \"clf__gamma\": [\"scale\", \"auto\"]},\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"clf__n_neighbors\": list(range(3, 11, 2)), \"clf__weights\": [\"uniform\", \"distance\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "results_tr = {}\n",
    "results_ts = {}\n",
    "cv_scores = {}\n",
    "feature_importances = {}\n",
    "\n",
    "# Run per model/map\n",
    "for measure in measures:\n",
    "    print(f\"Processing measure: {measure}\")\n",
    "    results_tr[measure] = []\n",
    "    results_ts[measure] = []\n",
    "    cv_scores[measure] = []\n",
    "    feature_importances[measure] = {}\n",
    "\n",
    "    # Load data\n",
    "    on_features_train = np.array(pd.read_csv(f\"{data_dir}/data_train/{measure}_ON.csv\"))\n",
    "    off_features_train = np.array(pd.read_csv(f\"{data_dir}/data_train/{measure}_OFF.csv\"))\n",
    "    on_features_test = np.array(pd.read_csv(f\"{data_dir}/data_test/{measure}_ON.csv\"))\n",
    "    off_features_test = np.array(pd.read_csv(f\"{data_dir}/data_test/{measure}_OFF.csv\"))\n",
    "\n",
    "    X_tr = np.concatenate((on_features_train, off_features_train), axis=0)\n",
    "    y_tr = np.concatenate([np.zeros(len(on_features_train)), np.ones(len(off_features_train))])\n",
    "    X_ts = np.concatenate((on_features_test, off_features_test), axis=0)\n",
    "    y_ts = np.concatenate([np.zeros(len(on_features_test)), np.ones(len(off_features_test))])\n",
    "\n",
    "    groups = np.concatenate((range(len(on_features_train)), range(len(off_features_train))))\n",
    "\n",
    "    for name, config in models.items():\n",
    "        print(f\"\\nRunning GridSearchCV for {name}...\")\n",
    "\n",
    "        pipe = Pipeline([(\"pca\", PCA()), (\"clf\", config[\"model\"])])\n",
    "\n",
    "        param_grid = [{\"pca\": [PCA(n_components=0.99), \"passthrough\"], **config[\"params\"]}]\n",
    "\n",
    "        group_kfold = GroupKFold(n_splits=5)\n",
    "        scoring = {\"roc_auc\": \"roc_auc\", \"accuracy\": \"accuracy\", \"f1\": \"f1\", \"recall\": \"recall\"}\n",
    "\n",
    "        grid = GridSearchCV(pipe, param_grid, cv=group_kfold, scoring=scoring, refit=\"accuracy\", n_jobs=-1)\n",
    "        grid.fit(X_tr, y_tr, groups=groups)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_ts)\n",
    "        y_proba = best_model.predict_proba(X_ts)[:, 1]\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        roc_auc = roc_auc_score(y_ts, y_proba)\n",
    "        accuracy = accuracy_score(y_ts, y_pred)\n",
    "        f1 = f1_score(y_ts, y_pred)\n",
    "        recall = recall_score(y_ts, y_pred)\n",
    "\n",
    "        clf = best_model.named_steps[\"clf\"]\n",
    "        pca_step = best_model.named_steps.get(\"pca\", None)\n",
    "\n",
    "        n_features = pca_step.n_components_ if isinstance(pca_step, PCA) else X_tr.shape[1]\n",
    "\n",
    "        if isinstance(clf, (LogisticRegression, LinearDiscriminantAnalysis)):\n",
    "            model_coef = clf.coef_[0]\n",
    "\n",
    "            if isinstance(pca_step, PCA):\n",
    "                loadings = pca_step.components_.T * np.sqrt(pca_step.explained_variance_)\n",
    "                importance = np.dot(loadings, model_coef)\n",
    "            else:\n",
    "                importance = model_coef\n",
    "\n",
    "            feature_importances[measure][name] = importance\n",
    "\n",
    "        results_ts[measure].append({\n",
    "            \"Model\": name,\n",
    "            \"ROC_AUC\": roc_auc,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "            \"num_features\": n_features,\n",
    "        })\n",
    "\n",
    "        # Save metrics\n",
    "        cv_scores[measure].append({\"Model\": name, \"CV_Score\": grid.best_score_, \"Best_Params\": grid.best_params_})\n",
    "\n",
    "        best_idx = grid.best_index_\n",
    "        results_tr[measure].append({\n",
    "            \"Model\": name,\n",
    "            \"ROC_AUC\": grid.cv_results_[\"mean_test_roc_auc\"][best_idx],\n",
    "            \"Accuracy\": grid.cv_results_[\"mean_test_accuracy\"][best_idx],\n",
    "            \"Recall\": grid.cv_results_[\"mean_test_recall\"][best_idx],\n",
    "            \"F1\": grid.cv_results_[\"mean_test_f1\"][best_idx],\n",
    "            \"num_features\": n_features,\n",
    "        })\n",
    "\n",
    "    # Save test results\n",
    "    with pd.ExcelWriter(output_dir + \"classification_performance_test_rev.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        for m in results_ts:\n",
    "            df_results = pd.DataFrame(results_ts[m])\n",
    "            df_results.to_excel(writer, sheet_name=m, index=False)\n",
    "\n",
    "    # Save feature importances\n",
    "    with pd.ExcelWriter(\n",
    "        output_dir + \"classification_features_importances_test_rev.xlsx\", engine=\"xlsxwriter\"\n",
    "    ) as feature_writer:\n",
    "        for m in feature_importances:\n",
    "            if feature_importances[m]:\n",
    "                df_feat = pd.DataFrame.from_dict(feature_importances[m], orient=\"index\").transpose()\n",
    "                df_feat.to_excel(feature_writer, sheet_name=m, index=False)\n",
    "\n",
    "    # Save CV results\n",
    "    with pd.ExcelWriter(\n",
    "        output_dir + \"classification_performance_train_cv_5_rev.xlsx\", engine=\"xlsxwriter\"\n",
    "    ) as cv_writer:\n",
    "        for m in results_tr:\n",
    "            df_cv = pd.DataFrame(results_tr[m])\n",
    "            df_cv.to_excel(cv_writer, sheet_name=m, index=False)\n",
    "\n",
    "    # Save best params\n",
    "    with pd.ExcelWriter(output_dir + \"classification_best_parameters.xlsx\", engine=\"xlsxwriter\") as cv_score_writer:\n",
    "        for m in cv_scores:\n",
    "            df_cv_best = pd.DataFrame(cv_scores[m])\n",
    "            df_cv_best.to_excel(cv_score_writer, sheet_name=m, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8a41e",
   "metadata": {},
   "source": [
    "### Correlation with clinical scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18da2c",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = pd.read_excel(\"../data/clida/clida.xlsx\", sheet_name=0)\n",
    "test_scores = pd.read_excel(\"../data/clida/clida.xlsx\", sheet_name=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5313b1f",
   "metadata": {},
   "source": [
    "#### Load atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f996ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_path = \"../data/msk/rAAL.nii\"\n",
    "label_txt_path = \"../data/msk/aal_labels.txt\"\n",
    "\n",
    "atlas_img = nib.load(atlas_path)\n",
    "atlas_data = atlas_img.get_fdata().astype(int)\n",
    "roi_ids = np.unique(atlas_data)[1:]\n",
    "\n",
    "label_map = pd.read_csv(label_txt_path, sep=r\"\\s+\", header=None, names=[\"Region\", \"Index\"])\n",
    "label_map[\"Index\"] = label_map[\"Index\"].astype(int)\n",
    "roi_dict = dict(zip(label_map[\"Index\"], label_map[\"Region\"], strict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e168d",
   "metadata": {},
   "source": [
    "#### Compute correlations with regional importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_path = output_dir + \"classification_features_importances_test_rev.xlsx\"\n",
    "measures = [\"ECM_deg\", \"ECM_norm\", \"ECM_rank\", \"GCOR\"]\n",
    "\n",
    "results_corr = {}\n",
    "\n",
    "for measure in measures:\n",
    "    print(f\"\\nProcessing measure: {measure}\")\n",
    "    df_feat = pd.read_excel(feature_importances_path, sheet_name=measure)\n",
    "\n",
    "    on_features_train = np.array(pd.read_csv(f\"{data_dir}/data_train/{measure}_ON.csv\"))\n",
    "    off_features_train = np.array(pd.read_csv(f\"{data_dir}/data_train/{measure}_OFF.csv\"))\n",
    "\n",
    "    for model_name in df_feat.columns:\n",
    "        importance_scores = df_feat[model_name].to_numpy()\n",
    "\n",
    "        on_weighted = on_features_train * importance_scores\n",
    "        off_weighted = off_features_train * importance_scores\n",
    "\n",
    "        roi_df_on = []\n",
    "        roi_df_off = []\n",
    "\n",
    "        for subj_idx in range(on_weighted.shape[0]):\n",
    "            subj_img_on = nilearn.masking.unmask(on_weighted[subj_idx], mask_img)\n",
    "            subj_img_off = nilearn.masking.unmask(off_weighted[subj_idx], mask_img)\n",
    "\n",
    "            subj_data_on = subj_img_on.get_fdata()\n",
    "            subj_data_off = subj_img_off.get_fdata()\n",
    "\n",
    "            row_on = {}\n",
    "            row_off = {}\n",
    "\n",
    "            for roi in roi_ids:\n",
    "                roi_vox_on = subj_data_on[atlas_data == roi]\n",
    "                roi_vox_off = subj_data_off[atlas_data == roi]\n",
    "\n",
    "                row_on[roi_dict[roi]] = roi_vox_on.mean() if roi_vox_on.size > 0 else np.nan\n",
    "                row_off[roi_dict[roi]] = roi_vox_off.mean() if roi_vox_off.size > 0 else np.nan\n",
    "\n",
    "            roi_df_on.append(row_on)\n",
    "            roi_df_off.append(row_off)\n",
    "\n",
    "        roi_df_on = pd.DataFrame(roi_df_on)\n",
    "        roi_df_off = pd.DataFrame(roi_df_off)\n",
    "\n",
    "        roi_df_on[\"score_on\"] = train_scores[\"MDSUPDRSIIIDBSON\"][: len(roi_df_on)].to_numpy()\n",
    "        roi_df_off[\"score_off\"] = train_scores[\"MDSUPDRSIIIDBSOFF\"][: len(roi_df_off)].to_numpy()\n",
    "\n",
    "        roi_df_on = roi_df_on.dropna(subset=[\"score_on\"])\n",
    "        roi_df_off = roi_df_off.dropna(subset=[\"score_off\"])\n",
    "\n",
    "        score_on = roi_df_on[\"score_on\"].to_numpy()\n",
    "        score_off = roi_df_off[\"score_off\"].to_numpy()\n",
    "        score_diff = score_off - score_on\n",
    "\n",
    "        corr_on_on = roi_df_on.drop(columns=[\"score_on\"]).corrwith(roi_df_on[\"score_on\"])\n",
    "        corr_off_off = roi_df_off.drop(columns=[\"score_off\"]).corrwith(roi_df_off[\"score_off\"])\n",
    "        corr_on_diff = roi_df_on.drop(columns=[\"score_on\"]).corrwith(pd.Series(score_diff, index=roi_df_on.index))\n",
    "        corr_off_diff = roi_df_off.drop(columns=[\"score_off\"]).corrwith(pd.Series(score_diff, index=roi_df_off.index))\n",
    "\n",
    "        corr_df = pd.DataFrame({\n",
    "            \"DBS-ON to MDSUPDRSIII-ON\": corr_on_on,\n",
    "            \"DBS-OFF to MDSUPDRSIII-OFF\": corr_off_off,\n",
    "            \"DBS-ON to MDSUPDRSIII-DIFF\": corr_on_diff,\n",
    "            \"DBS-OFF to MDSUPDRSIII-DIFF\": corr_off_diff,\n",
    "        })\n",
    "\n",
    "        results_corr[measure, model_name] = corr_df\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"../results/scores/correlations_train.xlsx\") as writer:\n",
    "    for (measure, algo), df in results_corr.items():\n",
    "        sheet_name = f\"{measure}_{algo}\"\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c37c3d",
   "metadata": {},
   "source": [
    "#### Visualize with heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0cfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\", \"LDA\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(18, 12), sharex=True, sharey=False)\n",
    "all_values = []\n",
    "\n",
    "for measure in measures:\n",
    "    for model_name in models:\n",
    "        corr_df = results_corr[measure, model_name]\n",
    "        corr_df[\"abs_max\"] = corr_df.abs().max(axis=1)\n",
    "        top50 = corr_df.sort_values(\"abs_max\", ascending=False).head(20)\n",
    "        corr_plot_top = top50.drop(columns=[\"abs_max\"])\n",
    "        all_values.append(corr_plot_top.values)\n",
    "\n",
    "all_values = np.concatenate(all_values).flatten()\n",
    "vmin, vmax = all_values.min(), all_values.max()\n",
    "\n",
    "for col, measure in enumerate(measures):\n",
    "    for row, model_name in enumerate(models):\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        corr_df = results_corr[measure, model_name]\n",
    "        corr_df[\"abs_max\"] = corr_df.abs().max(axis=1)\n",
    "        top50 = corr_df.sort_values(\"abs_max\", ascending=False).head(20)\n",
    "        corr_plot_top = top50.drop(columns=[\"abs_max\"])\n",
    "\n",
    "        sns.heatmap(\n",
    "            corr_plot_top,\n",
    "            ax=ax,\n",
    "            cmap=\"PuOr_r\",\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cbar=False,\n",
    "        )\n",
    "\n",
    "        if row == 0:\n",
    "            ax.set_title(measure, fontsize=16)\n",
    "\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(model_name, fontsize=16)\n",
    "\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_yticklabels([lbl.get_text().replace(\"_\", \" \") for lbl in ax.get_yticklabels()])\n",
    "\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "norm = plt.cm.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"PuOr_r\", norm=norm)\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "plt.savefig(\"correlations_train.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
